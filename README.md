# Sentiment-Analysis (On going)
A project to analyze and predict sentiment using XLM-RoBERTa which is a large, multilingual language model trained on a massive dataset covering 100 different languages

# Overview
This project aims to classify text data into positive, negative, and/or neutral sentiments from more than 7+ languages usch as Arabic, English, Indonesian, Hindi, etc. The model is trained on various merged AI datasets and demonstrates the complete workflow of a typical NLP project, from data preprocessing and Exploratory Data Analysis (EDA) to model training and evaluation.

# Key Features
**• Data Cleaning & Preprocessing**: Implemented techniques like lowercasing, URLs removal, emoji conversion, punctuation removal, and tokenization.

**• Exploratory Data Analysis (EDA)**: Visualizations of word frequencies, sentiment distribution, and n-grams using libraries like Matplotlib and Seaborn.

**• Feature Engineering**: Converted text data into numerical vectors using [TF-IDF].

**• Machine Learning Model**: Built and trained a XLM-roBERTa model to predict sentiment.

**• Model Evaluation**: Assessed model performance using metrics such as Accuracy, Precision, Recall, and F1-Score.

# Tech Stack
Language: Python

Libraries:

• Pandas (Data manipulation and analysis)

• NLTK (Text preprocessing)

• RegEx (Regular Expression removal)

• Emoji (Emoji conversion)

• Scikit-learn (Metrics)

• Matplotlib / Seaborn (Data visualization)

• Jupyter Notebook (Project environment)

# Result

